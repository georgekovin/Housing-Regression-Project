{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> *Модель прогнозирования стоимости жилья для агентства недвижимости*\n",
    "\n",
    "# <center> **Часть II. Разведывательный анализ и моделирование.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as sps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.preprocessing as pp \n",
    "import sklearn.model_selection as ms \n",
    "import sklearn.feature_selection as fs\n",
    "\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn.tree as tree\n",
    "import sklearn.ensemble as ens\n",
    "import sklearn.svm as svm\n",
    "import sklearn.metrics as m\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import xgboost as xgb\n",
    "import catboost as cb \n",
    "\n",
    "from functions import *\n",
    "import pickle \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('bmh')\n",
    "\n",
    "R = 7\n",
    "np.random.seed(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Данные**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Читаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/data_edited.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Разведывательный анализ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование бинарных переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = set()\n",
    "num_cols = []\n",
    "\n",
    "for col in data.columns:\n",
    "    if ('target' not in col) and (data[col].nunique() == 2):\n",
    "        bin_cols.add(col.split()[0])\n",
    "    else:\n",
    "        num_cols.append(col)\n",
    "\n",
    "bin_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_barplot(cols, data=data, figsize=(20, 5)):\n",
    "    sums = get_sums(data, cols).sort_values(ascending=False)\n",
    "\n",
    "    col_list = sums.index.tolist() + ['all']\n",
    "    vls_list = sums.values.tolist() + [data.shape[0]]\n",
    "\n",
    "    for i in range(len(col_list)):\n",
    "        col_list[i] = col_list[i].replace(cols+' ', '')\n",
    "\n",
    "    df = (pd.DataFrame({'labels': col_list, \n",
    "                        'count': vls_list})\n",
    "          .sort_values('count', ascending=False))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.barplot(df, x='labels', y='count', hue='labels', ax=ax)\n",
    "    ax.tick_params(rotation=30)\n",
    "    ax.set_title(cols)\n",
    "    \n",
    "    return fig \n",
    "\n",
    "\n",
    "for col in bin_cols:\n",
    "    show_barplot(col).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на нормальность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_normality(labels, \n",
    "                   data=data, \n",
    "                   testfunc='shapiro', \n",
    "                   alpha=0.05):\n",
    "    \n",
    "    norm_df = pd.DataFrame(index=labels)\n",
    "    \n",
    "    pv_list = []\n",
    "    for col in data[labels].columns:\n",
    "        x = data[col]\n",
    "        \n",
    "        if testfunc == 'dagostino':\n",
    "            p = sps.normaltest(x)\n",
    "            pv = round(p.pvalue[0], 3)\n",
    "            alpha = alpha / 2\n",
    "\n",
    "        p = sps.shapiro(x)\n",
    "        pv = round(p.pvalue, 3)\n",
    "        \n",
    "        pv_list.append(pv)\n",
    "    \n",
    "    norm_df['p_value'] = pv_list\n",
    "    norm_df['is_normal'] = norm_df['p_value'].apply(lambda pv: 'normal' if pv > alpha else 'not normal')\n",
    "\n",
    "    return norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normality(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выявление и очистка выбросов "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(features, data=data, q_limit=0.99, show_plot=False):\n",
    "    cleaned = data.copy()\n",
    "    \n",
    "    for feature in features:\n",
    "        x = cleaned[feature]\n",
    "\n",
    "        lim = x.quantile(q_limit)\n",
    "        cleaned = cleaned[x <= lim][x >= -lim].reset_index(drop=True)\n",
    "        \n",
    "    print(f'Shape of cleaned data is {cleaned.shape}.')\n",
    "    print(f'{data.shape[0] - cleaned.shape[0]} outliers were dropped.')\n",
    "        \n",
    "    if show_plot:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(15, 15))\n",
    "        \n",
    "        sns.kdeplot(data[features], ax=ax[0])\n",
    "        ax[0].set_ylabel('Original distribution')\n",
    "\n",
    "        sns.kdeplot(cleaned[features], ax=ax[1])\n",
    "        ax[1].set_ylabel('Cleaned distribution')\n",
    "\n",
    "        fig.show()\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "cleaned_data = clean_data(num_cols, show_plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на мультиколлинеарность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations(method, data=cleaned_data):\n",
    "    corr_data = (data.corr(method=method)\n",
    "                 [data.corr(method=method).abs() > 0.9]\n",
    "                 .round(2))\n",
    "\n",
    "    for i in corr_data.index:\n",
    "        for c in corr_data.columns:\n",
    "            if i == c:\n",
    "                corr_data.loc[i, c] = np.nan\n",
    "\n",
    "    for i, c in zip(corr_data.index, \n",
    "                    corr_data.columns):\n",
    "        if corr_data.loc[i].sum() == 0:\n",
    "            corr_data.drop(i, axis=0, inplace=True)\n",
    "        if corr_data.loc[:, c].sum() == 0:\n",
    "            corr_data.drop(c, axis=1, inplace=True)\n",
    "            \n",
    "    return corr_data\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(30, 10))\n",
    "\n",
    "sns.heatmap(get_correlations('pearson'), \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            linewidths=.5, \n",
    "            linecolor='grey', \n",
    "            ax=ax[0])\n",
    "ax[0].set_title(\"Pearson's correlation\")\n",
    "\n",
    "sns.heatmap(get_correlations('spearman'), \n",
    "            annot=True, \n",
    "            cmap='coolwarm', \n",
    "            linewidths=.5, \n",
    "            linecolor='grey', \n",
    "            ax=ax[1])\n",
    "ax[1].set_title(\"Spearman's correlation\")\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multicollinear_cols = ['heating forced', 'cooling system', 'parking none', \n",
    "                       'parking door opener', 'city importance']\n",
    "\n",
    "cleaned_data.drop(multicollinear_cols, axis=1, inplace=True)\n",
    "\n",
    "cleaned_data.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследования по выборкам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_stattest(data, alpha=0.05):\n",
    "    bins_list = []\n",
    "\n",
    "    for col in data.columns:\n",
    "        if data[col].nunique() == 2:\n",
    "            bins_list.append(col)\n",
    "            \n",
    "    statdata = pd.DataFrame(index=bins_list)\n",
    "    pv_list = []\n",
    "    dep_list = []\n",
    "            \n",
    "    for col_ in bins_list:\n",
    "        sample_1 = data[data[col_] == 1]\n",
    "        sample_0 = data[data[col_] == 0]\n",
    "        \n",
    "        _, p = sps.mannwhitneyu(sample_0['target'], \n",
    "                                sample_1['target'])\n",
    "        pv_list.append(p)\n",
    "        \n",
    "        if p > alpha:\n",
    "            dep_list.append(0)\n",
    "        else:\n",
    "            dep_list.append(1)\n",
    "            \n",
    "    statdata['pvalue'] = pv_list\n",
    "    statdata['depends'] = dep_list\n",
    "    \n",
    "    return statdata\n",
    "\n",
    "\n",
    "bs_data = binary_stattest(cleaned_data)\n",
    "\n",
    "useless_df = bs_data[bs_data['depends'] == 0]\n",
    "\n",
    "useless_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.drop(useless_df.index, axis=1, inplace=True)\n",
    "\n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование числовых переменных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = []\n",
    "\n",
    "for col in cleaned_data.columns:\n",
    "    if cleaned_data[col].nunique() > 2:\n",
    "        num_cols.append(col)\n",
    "\n",
    "num_cols.remove('target')\n",
    "\n",
    "numdata_info = get_data_info(cleaned_data[num_cols])\n",
    "\n",
    "numdata_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Категориальные*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = numdata_info[numdata_info['Uniques'] <= 20].index.tolist()\n",
    "\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_stattest(data, cols=cat_cols, alpha=0.05):\n",
    "    statdata = pd.DataFrame(index=cols)\n",
    "    pv_list = []\n",
    "    dep_list = []\n",
    "    \n",
    "    for c in cols:\n",
    "        samples = []\n",
    "\n",
    "        for i in data[c].unique():\n",
    "            sample = data[data[c] == i]\n",
    "            samples.append(sample['target'])\n",
    "            \n",
    "        _, p = sps.kruskal(*samples)\n",
    "        \n",
    "        pv_list.append(p)\n",
    "        \n",
    "        \n",
    "        if p > alpha:\n",
    "            dep_list.append(0)\n",
    "        else:\n",
    "            dep_list.append(1)\n",
    "            \n",
    "    statdata['pvalue'] = pv_list\n",
    "    statdata['depends'] = dep_list\n",
    "    \n",
    "            \n",
    "    return statdata\n",
    "\n",
    "\n",
    "multiple_stattest(cleaned_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Непрерывные*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in cat_cols:\n",
    "    num_cols.remove(cat)\n",
    "    \n",
    "num_cols, len(num_cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6, 2, figsize=(20, 30))\n",
    "\n",
    "for i, col in enumerate(num_cols):\n",
    "    sample = cleaned_data[[col, 'target']].sample(1000, random_state=R)\n",
    "\n",
    "    if i % 2 == 0:\n",
    "        ax_place = ax[i//2, 0]\n",
    "    else:\n",
    "        ax_place = ax[i//2, 1]\n",
    "        \n",
    "    sns.scatterplot(sample, x=col, y='target', ax=ax_place)\n",
    "    \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Масштабирование данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20, 20))\n",
    "\n",
    "num_cols += cat_cols\n",
    "\n",
    "sns.kdeplot(cleaned_data[num_cols], ax=ax[0])\n",
    "ax[0].set_ylabel('Original distribution')\n",
    "\n",
    "scaler = pp.MinMaxScaler()\n",
    "nums_scaled = pd.DataFrame(scaler.fit_transform(cleaned_data[num_cols]),\n",
    "                           columns=scaler.feature_names_in_)\n",
    "\n",
    "sns.kdeplot(nums_scaled, ax=ax[1])\n",
    "ax[1].set_ylabel('Scaled distribution')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data[num_cols] = nums_scaled\n",
    "\n",
    "cleaned_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Моделирование**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Деление данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = (cleaned_data\n",
    "          .query('target == 0')\n",
    "          .drop('target', axis=1))\n",
    "\n",
    "cleaned_data.drop(X_eval.index, axis=0, inplace=True)\n",
    "\n",
    "X = cleaned_data.drop(['target'], axis=1)\n",
    "y = cleaned_data['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, \n",
    "                                                       test_size=0.2, \n",
    "                                                       random_state=R)\n",
    "\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, X_eval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор самых сильных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = fs.SelectKBest(score_func=fs.f_regression, k=20)\n",
    "selector.fit(X_train, y_train)\n",
    "\n",
    "best_feats = selector.get_feature_names_out()\n",
    "\n",
    "X_train = X_train[best_feats]\n",
    "X_test = X_test[best_feats]\n",
    "X_eval = X_eval[best_feats]\n",
    "\n",
    "selector_scores = pd.DataFrame({'features': selector.feature_names_in_, \n",
    "                                'statistic': selector.scores_})\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.barplot(selector_scores.sort_values('statistic', ascending=False)[:20], \n",
    "            y='features', \n",
    "            x='statistic', \n",
    "            orient='h').set_title('Feature Importance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame(columns=['MAE_train', 'MAE_test', 'MAE_difference', \n",
    "                               'MAPE_train', 'MAPE_test', 'MAPE_difference',\n",
    "                               'R2_train', 'R2_test', 'R2_difference', \n",
    "                               'Model'])\n",
    "\n",
    "\n",
    "def regression_estimate(model, \n",
    "                        X_train=X_train, \n",
    "                        y_train=y_train, \n",
    "                        X_test=X_test, \n",
    "                        y_test=y_test, \n",
    "                        params=None):\n",
    "    metric_dict = {}\n",
    "    \n",
    "    if params is not None:\n",
    "        rs = ms.RandomizedSearchCV(estimator=model, \n",
    "                                   param_distributions=params, \n",
    "                                   random_state=R, cv=5, n_jobs=-1) \n",
    "        rs.fit(X_train, y_train)\n",
    "        \n",
    "        model = rs.best_estimator_\n",
    "    \n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    mae = lambda y_true, y_pred: m.mean_absolute_error(y_true, y_pred).round(2)\n",
    "    mape = lambda y_true, y_pred: m.mean_absolute_percentage_error(y_true, y_pred).round(2)\n",
    "    \n",
    "    metric_dict['MAE_train'] = mae(y_train, train_pred)\n",
    "    metric_dict['MAE_test'] = mae(y_test, test_pred)\n",
    "    metric_dict['MAE_difference'] = np.abs(metric_dict['MAE_train'] - \n",
    "                                           metric_dict['MAE_test'])\n",
    "    \n",
    "    metric_dict['MAPE_train'] = mape(y_train, train_pred)\n",
    "    metric_dict['MAPE_test'] = mape(y_test, test_pred)\n",
    "    metric_dict['MAPE_difference'] = np.abs(metric_dict['MAPE_train'] - \n",
    "                                            metric_dict['MAPE_test'])\n",
    "    \n",
    "    metric_dict['R2_train'] = m.r2_score(y_train, train_pred).round(2)\n",
    "    metric_dict['R2_test'] = m.r2_score(y_test, test_pred).round(2)\n",
    "    metric_dict['R2_difference'] = np.abs(metric_dict['R2_train'] - \n",
    "                                          metric_dict['R2_test'])\n",
    "    \n",
    "    metric_dict['Model'] = model\n",
    "    \n",
    "    return metric_dict\n",
    "\n",
    "\n",
    "def add_metrics_model(model_name, metrics, data=models):    \n",
    "    data.loc[model_name] = metrics\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "model_loc = lambda model: models.loc[model, 'Model']\n",
    "\n",
    "\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Линейная регрессия (baseline)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LinearRegression()\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Linear', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Полиномиальная регрессия*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynom = pp.PolynomialFeatures(degree=2)\n",
    "polynom.fit(X_train)\n",
    "\n",
    "X_train_polynom = polynom.transform(X_train)\n",
    "X_test_polynom = polynom.transform(X_test)\n",
    "\n",
    "metrics = regression_estimate(model, \n",
    "                              X_train=X_train_polynom, \n",
    "                              X_test=X_test_polynom)\n",
    "\n",
    "add_metrics_model('Polynomial', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор модели с параметрами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Стохастический градиентный спуск*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.SGDRegressor(random_state=R)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('SGD', metrics).loc[['SGD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_iter': [1000, 1e4], \n",
    "          'learning_rate': ['invscaling', 'constant'], \n",
    "          'eta0': [0.01, 0.001, 0.0001]}\n",
    "\n",
    "metrics = regression_estimate(model, params=params)\n",
    "\n",
    "add_metrics_model('SGD', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('SGD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Дерево решений*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeRegressor(random_state=R)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Decision Tree', metrics).loc[['Decision Tree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [6, 8, 10], \n",
    "          'min_samples_split': [1, 2, 3], \n",
    "          'min_samples_leaf': [1, 2, 3, 4]}\n",
    "\n",
    "metrics = regression_estimate(model, params=params)\n",
    "\n",
    "add_metrics_model('Decision Tree', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('Decision Tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Случайный лес*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.RandomForestRegressor(random_state=R, n_jobs=-1)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Random Forest', metrics).loc[['Random Forest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.RandomForestRegressor(n_estimators=500, \n",
    "                                  max_depth=10,\n",
    "                                  min_samples_leaf=3,\n",
    "                                  random_state=R, n_jobs=-1)\n",
    "\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Random Forest', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Стекинг*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('lr', model_loc('Linear')), \n",
    "              ('sgd', model_loc('SGD')), \n",
    "              ('dt', model_loc('Decision Tree'))]\n",
    "final_estimator = ens.RandomForestRegressor(max_depth=10, random_state=R)\n",
    "\n",
    "model = ens.StackingRegressor(estimators=estimators, \n",
    "                              final_estimator=final_estimator, \n",
    "                              cv=5, n_jobs=-1)\n",
    "\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Stacking', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('Stacking') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Адаптивный бустинг*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.AdaBoostRegressor(random_state=R)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Adaptive Boosting', metrics).loc[['Adaptive Boosting']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.AdaBoostRegressor(estimator=model_loc('Decision Tree'), \n",
    "                              n_estimators=100, \n",
    "                              random_state=R)\n",
    "\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Adaptive Boosting', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('Adaptive Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Градиентный бустинг*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.GradientBoostingRegressor(random_state=R)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Gradient Boosting', metrics).loc[['Gradient Boosting']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.GradientBoostingRegressor(n_estimators=300, \n",
    "                                      criterion='squared_error',\n",
    "                                      max_depth=6, \n",
    "                                      random_state=R)\n",
    "\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Gradient Boosting', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('Gradient Boosting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Бустинг-регрессия от `xgboost`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor()\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('XGBoost', metrics).loc[['XGBoost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(n_estimators=500, \n",
    "                         max_depth=6, \n",
    "                         eta=0.1,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('XGBoost', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Регрессия от `LightGBM`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm.LGBMRegressor(random_state=R, n_jobs=-1)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('LightGBM', metrics).loc[['LightGBM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [3, 5, 10], \n",
    "          'n_estimators': [100, 300, 500], \n",
    "          'learning_rate': [0.1, 0.01]} \n",
    "\n",
    "metrics = regression_estimate(model, params=params)\n",
    "\n",
    "add_metrics_model('LightGBM', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('LightGBM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Регрессия от `CatBoost`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cb.CatBoostRegressor(random_state=R, verbose=False)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('CatBoost', metrics).loc[['CatBoost']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cb.CatBoostRegressor(learning_rate=0.01, \n",
    "                             max_depth=10,\n",
    "                             n_estimators=1000,  \n",
    "                             eval_metric='MAE', \n",
    "                             random_state=R, verbose=False)\n",
    "\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('CatBoost', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loc('CatBoost').get_all_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочие модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Экстра-дерево*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.ExtraTreeRegressor(random_state=R)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Extra Tree', metrics).loc[['Extra Tree']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(**model_loc('Decision Tree').get_params())\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Extra Tree', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Экстра-лес*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ens.ExtraTreesRegressor(random_state=R, n_jobs=-1)\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Extra Trees', metrics).loc[['Extra Trees']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(**model_loc('Random Forest').get_params())\n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Extra Trees', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Голосующая регрессия*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('et', model_loc('Extra Tree')), \n",
    "              ('ef', model_loc('Extra Trees'))]\n",
    "\n",
    "model = ens.VotingRegressor(estimators=estimators, n_jobs=-1) \n",
    "metrics = regression_estimate(model)\n",
    "\n",
    "add_metrics_model('Voting', metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор модели и улучшение ее качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_accurate_model  = (models\n",
    "                        .query('(R2_test >= 0.5) & (MAPE_test <= 5)')\n",
    "                        .sort_values('MAPE_test')\n",
    "                        .iloc[0]['Model']) \n",
    "\n",
    "most_accurate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_overfitted_model = (models\n",
    "                          .query('(R2_test >= 0.5) & (MAPE_test <= 5)')\n",
    "                          .sort_values('MAE_difference')\n",
    "                          .iloc[0]['Model'])\n",
    "\n",
    "least_overfitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "        \"max_depth\": [3, 4, 5, 6, 8, 10, 12, 15],\n",
    "        \"min_child_weight\": [1, 3, 5, 7],\n",
    "        \"gamma\": [0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "        \"colsample_bytree\": [0.3, 0.4, 0.5 , 0.7]}\n",
    "\n",
    "metrics = regression_estimate(model, params=params)\n",
    "\n",
    "metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
